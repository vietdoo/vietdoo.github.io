{"version":3,"sources":["drawFace.js","App.js","reportWebVitals.js","index.js"],"names":["drawMesh","predictions","ctx","length","forEach","prediction","keypoints","scaledMesh","i","x","y","beginPath","arc","Math","PI","fillStyle","fill","App","webcam","useRef","canvas","init","a","setupCamera","current","width","height","console","log","Promise","resolve","reject","navigator","getUserMedia","video","stream","srcObject","addEventListener","error","meshF","runFaceMesh","facemesh","inputResolution","net","setInterval","detect","playcanvas","getContext","drawImage","clearInterval","estimateFaces","face","useEffect","className","ref","autoPlay","id","onClick","reportWebVitals","onPerfEntry","Function","then","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","render","StrictMode","document","getElementById"],"mappings":"iWACaA,G,OAAW,SAACC,EAAaC,GAC9BD,EAAYE,OAAS,GACvBF,EAAYG,SAAQ,SAACC,GAInB,IAHA,IAAMC,EAAYD,EAAWE,WAGpBC,EAAI,EAAGA,EAAIF,EAAUH,OAAQK,IAAK,CACzC,IAAMC,EAAIH,EAAUE,GAAG,GACjBE,EAAIJ,EAAUE,GAAG,GAEvBN,EAAIS,YACJT,EAAIU,IAAIH,EAAGC,EAAG,EAAG,EAAG,EAAIG,KAAKC,IAC7BZ,EAAIa,UAAY,OAChBb,EAAIc,a,QCgHCC,MAxHf,WAEE,IAAMC,EAASC,mBACTC,EAASD,mBAITE,GAHkBF,mBAGd,uCAAG,sBAAAG,EAAA,sEACLC,IADK,OAEXH,EAAOI,QAAQC,MAAQ,IACvBL,EAAOI,QAAQE,OAAS,IACxBC,QAAQC,IAAI,wBAJD,2CAAH,sDAOJL,EAAc,WAClB,OAAO,IAAIM,SAAQ,SAACC,EAASC,GAC3BC,UAAUC,aAAeD,UAAUC,aAC/BD,UAAUC,aACZD,UAAUC,aACR,CAACC,OAAO,IACR,SAAAC,GACEjB,EAAOM,QAAQY,UAAYD,EAC3BjB,EAAOM,QAAQa,iBAAiB,aAAcP,MAEhD,SAAAQ,GAAK,OAAIP,EAAOO,MAGlBP,QAoBFQ,EAAQ,KAENC,EAAW,uCAAG,4BAAAlB,EAAA,sEACAmB,IAAe,CAC/BC,gBAAiB,CAACjB,MAAO,IAAKC,OAAO,OAFrB,OACZiB,EADY,OAIlBJ,EAAQK,aAAY,WAClBC,EAAOF,KACN,IANe,2CAAH,qDAiBbG,EAAaF,aARD,WACd,GAA8B,qBAAnB1B,EAAOM,QAAyB,CACzC,IAAMU,EAAQhB,EAAOM,QACTJ,EAAOI,QAAQuB,WAAW,MAClCC,UAAUd,EAAO,EAAG,MAIU,IAEhCW,EAAM,uCAAG,WAAOF,GAAP,mBAAArB,EAAA,yDACb2B,cAAcH,GACgB,qBAAnB5B,EAAOM,QAFL,wBAGLU,EAAQhB,EAAOM,QAHV,SAKQmB,EAAIO,cAAchB,GAL1B,OAKLiB,EALK,OAMXxB,QAAQC,IAAIuB,IAGNjD,EAAMkB,EAAOI,QAAQuB,WAAW,OAClCC,UAAUd,EAAO,EAAG,GACxBlC,EAASmD,EAAMjD,GAXJ,4CAAH,sDA6BZ,OARAkD,qBAAW,WAGT,OAFA/B,IAEO,eAGN,IAGD,sBAAKgC,UAAU,OAAf,qCAEE,uBACEC,IAAKpC,EACLmC,UAAU,QACVE,UAAQ,IAEV,wBACED,IAAKlC,EACLiC,UAAU,WAEZ,sBAAKA,UAAU,UAAf,UACG,wBAAQA,UAAU,MAAMG,GAAK,KAAKC,QAAS,kBAAMjB,KAAjD,kBACA,wBAAQa,UAAU,MAAMG,GAAK,KAAKC,QAAS,kBA3BhDR,cAAcV,GACdnB,EAAOI,QAAQC,MAAQ,SACvBL,EAAOI,QAAQE,OAAS,MAyBnB,yBCzGMgC,EAZS,SAAAC,GAClBA,GAAeA,aAAuBC,UACxC,8BAAqBC,MAAK,YAAkD,IAA/CC,EAA8C,EAA9CA,OAAQC,EAAsC,EAAtCA,OAAQC,EAA8B,EAA9BA,OAAQC,EAAsB,EAAtBA,OAAQC,EAAc,EAAdA,QAC3DJ,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAON,GACPO,EAAQP,OCDdQ,IAASC,OACP,cAAC,IAAMC,WAAP,UACE,cAAC,EAAD,MAEFC,SAASC,eAAe,SAM1Bb,M","file":"static/js/main.6fac98dc.chunk.js","sourcesContent":["\r\nexport const drawMesh = (predictions, ctx) => {\r\n    if (predictions.length > 0) {\r\n      predictions.forEach((prediction) => {\r\n        const keypoints = prediction.scaledMesh;\r\n  \r\n        // Draw Dots\r\n        for (let i = 0; i < keypoints.length; i++) {\r\n          const x = keypoints[i][0];\r\n          const y = keypoints[i][1];\r\n  \r\n          ctx.beginPath();\r\n          ctx.arc(x, y, 1, 0, 3 * Math.PI);\r\n          ctx.fillStyle = \"aqua\";\r\n          ctx.fill();\r\n        }\r\n      });\r\n    }\r\n  };","import './css/App.css';\nimport { useRef , useEffect } from 'react';\nimport * as facemesh from'@tensorflow-models/facemesh';\nimport * as tf from '@tensorflow/tfjs';\nimport { drawMesh } from \"./drawFace\";\n\nfunction App() {\n\n  const webcam = useRef();\n  const canvas = useRef();\n  const mobilenetModule = useRef();\n\n  //var ctx = canvas.getContext('2d');\n  const init = async () => {\n    await setupCamera();\n    canvas.current.width = 640;\n    canvas.current.height = 360;\n    console.log(\"setup camera done !!\");\n  }\n\n  const setupCamera = () => {\n    return new Promise((resolve, reject) => {\n      navigator.getUserMedia = navigator.getUserMedia\n      if (navigator.getUserMedia) {\n        navigator.getUserMedia(\n          {video: true},\n          stream => {\n            webcam.current.srcObject = stream;\n            webcam.current.addEventListener('loadeddata', resolve);\n          },\n          error => reject(error)\n        );\n      } else {\n        reject();\n      }\n    });\n  };\n\n  const drawPath = (ctx, points, closePath) => {\n    const region = new Path2D();\n    region.moveTo(points[0][0], points[0][1]);\n    for (let i = 1; i < points.length; i++) {\n      const point = points[i];\n      region.lineTo(point[0], point[1]);\n    }\n  \n    if (closePath) {\n      region.closePath();\n    }\n    ctx.strokeStyle = \"grey\";\n    ctx.stroke(region);\n  };\n\n  var meshF = null;\n\n  const runFaceMesh = async () => {\n    const net = await facemesh.load ({\n      inputResolution: {width: 640, height:360}\n    })\n    meshF = setInterval(() => {\n      detect(net)\n    }, 50)\n  }\n\n  const playcam = () => {\n    if (typeof webcam.current !== \"undefined\") {\n      const video = webcam.current;\n      const ctx = canvas.current.getContext(\"2d\");\n      ctx.drawImage(video, 0, 0);\n    }\n  }\n\n  var playcanvas = setInterval(playcam, 33);\n\n  const detect = async (net) => {\n    clearInterval(playcanvas);\n    if (typeof webcam.current !== \"undefined\") {\n      const video = webcam.current;\n      \n      const face = await net.estimateFaces(video);\n      console.log(face);\n      \n\n      const ctx = canvas.current.getContext(\"2d\");\n      ctx.drawImage(video, 0, 0);\n      drawMesh(face, ctx);\n    }\n  }\n\n  const stopProgram = () => {\n    clearInterval(meshF);\n    canvas.current.width = 640;\n    canvas.current.height = 360;\n  }\n\n  useEffect (() => {\n    init();\n    \n    return () => {\n\n    }\n  }, []);\n\n  return (\n    <div className=\"main\">\n      Face Landmark by vietdoo\n      <video\n        ref={webcam}\n        className=\"video\"\n        autoPlay\n      />\n      <canvas\n        ref={canvas}  \n        className=\"canvas\"    \n      />\n      <div className=\"control\">\n         <button className=\"btn\" id = \"b1\" onClick={() => runFaceMesh()}>Scan</button>\n         <button className=\"btn\" id = \"b2\" onClick={() => stopProgram()}>Stop</button>\n      </div>\n    </div>\n    \n    \n\n  );\n}\n\nexport default App;\n","const reportWebVitals = onPerfEntry => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n"],"sourceRoot":""}